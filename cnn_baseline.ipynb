{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ex4eCuv_qXHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e9076c-5b26-431e-f21b-08d2f51eb563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if not device_name:\n",
        "    raise SystemError('GPU device not found')\n",
        "print(f\"Found GPU at: {device_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flx-2uYFq4LO",
        "outputId": "a66ae4f1-392c-49e4-81c7-0689692f0e72"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets(train_dir, test_dir, img_size, batch_size):\n",
        "    raw_train = keras.preprocessing.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        color_mode=\"grayscale\",\n",
        "        image_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123\n",
        "    )\n",
        "    raw_val = keras.preprocessing.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        color_mode=\"grayscale\",\n",
        "        image_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123\n",
        "    )\n",
        "    raw_test = keras.preprocessing.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        color_mode=\"grayscale\",\n",
        "        image_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    class_names = raw_train.class_names\n",
        "\n",
        "    norm = layers.Rescaling(1./255)\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    train_ds = raw_train.map(lambda x,y:(norm(x),y)).cache().prefetch(AUTOTUNE)\n",
        "    val_ds   = raw_val  .map(lambda x,y:(norm(x),y)).cache().prefetch(AUTOTUNE)\n",
        "    test_ds  = raw_test .map(lambda x,y:(norm(x),y)).cache().prefetch(AUTOTUNE)\n",
        "\n",
        "    return train_ds, val_ds, test_ds, class_names"
      ],
      "metadata": {
        "id": "M1BBMHqaLGGI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn(input_shape, num_classes):\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0ZkWGcVQLJEk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    BASE_DIR  = \"/content/drive/MyDrive/COMP562_Project/data/processed\"\n",
        "    TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
        "    TEST_DIR  = os.path.join(BASE_DIR, \"test\")\n",
        "    IMG_SIZE  = 224\n",
        "    BATCH_SIZE= 32\n",
        "    EPOCHS    = 100\n",
        "\n",
        "    train_ds, val_ds, test_ds, class_names = get_datasets(\n",
        "        TRAIN_DIR, TEST_DIR, IMG_SIZE, BATCH_SIZE\n",
        "    )\n",
        "    num_classes = len(class_names)\n",
        "    print(\"Classes:\", class_names)\n",
        "\n",
        "    model = build_cnn((IMG_SIZE, IMG_SIZE, 1), num_classes)\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_ds\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_ds)\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "model, history = main()"
      ],
      "metadata": {
        "id": "s9Ym6eqLLL0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d14718f1-4c29-4358-d741-dbdb45278d63"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5715 files belonging to 4 classes.\n",
            "Using 4572 files for training.\n",
            "Found 5715 files belonging to 4 classes.\n",
            "Using 1143 files for validation.\n",
            "Found 1311 files belonging to 4 classes.\n",
            "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,784,068\u001b[0m (98.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,784,068</span> (98.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,784,068\u001b[0m (98.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,784,068</span> (98.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 162ms/step - accuracy: 0.5025 - loss: 1.1815 - val_accuracy: 0.8110 - val_loss: 0.5930\n",
            "Epoch 2/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.7922 - loss: 0.5441 - val_accuracy: 0.8399 - val_loss: 0.4540\n",
            "Epoch 3/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.8606 - loss: 0.3898 - val_accuracy: 0.8486 - val_loss: 0.4168\n",
            "Epoch 4/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.8743 - loss: 0.3229 - val_accuracy: 0.8565 - val_loss: 0.4040\n",
            "Epoch 5/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9125 - loss: 0.2369 - val_accuracy: 0.8574 - val_loss: 0.4230\n",
            "Epoch 6/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9232 - loss: 0.2050 - val_accuracy: 0.8933 - val_loss: 0.4274\n",
            "Epoch 7/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9477 - loss: 0.1469 - val_accuracy: 0.8959 - val_loss: 0.3879\n",
            "Epoch 8/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9605 - loss: 0.1076 - val_accuracy: 0.8793 - val_loss: 0.4844\n",
            "Epoch 9/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9681 - loss: 0.0848 - val_accuracy: 0.9134 - val_loss: 0.4047\n",
            "Epoch 10/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9796 - loss: 0.0596 - val_accuracy: 0.9213 - val_loss: 0.4021\n",
            "Epoch 11/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9865 - loss: 0.0383 - val_accuracy: 0.9073 - val_loss: 0.4834\n",
            "Epoch 12/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9860 - loss: 0.0428 - val_accuracy: 0.9011 - val_loss: 0.4520\n",
            "Epoch 13/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9866 - loss: 0.0376 - val_accuracy: 0.9213 - val_loss: 0.4414\n",
            "Epoch 14/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9877 - loss: 0.0290 - val_accuracy: 0.9116 - val_loss: 0.4222\n",
            "Epoch 15/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9911 - loss: 0.0251 - val_accuracy: 0.9116 - val_loss: 0.4433\n",
            "Epoch 16/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9925 - loss: 0.0260 - val_accuracy: 0.9090 - val_loss: 0.4139\n",
            "Epoch 17/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9898 - loss: 0.0352 - val_accuracy: 0.9178 - val_loss: 0.4908\n",
            "Epoch 18/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9928 - loss: 0.0220 - val_accuracy: 0.9160 - val_loss: 0.5129\n",
            "Epoch 19/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9937 - loss: 0.0171 - val_accuracy: 0.9064 - val_loss: 0.5768\n",
            "Epoch 20/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9903 - loss: 0.0284 - val_accuracy: 0.9143 - val_loss: 0.5387\n",
            "Epoch 21/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9894 - loss: 0.0302 - val_accuracy: 0.9081 - val_loss: 0.4588\n",
            "Epoch 22/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9925 - loss: 0.0177 - val_accuracy: 0.9125 - val_loss: 0.4912\n",
            "Epoch 23/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9948 - loss: 0.0145 - val_accuracy: 0.9230 - val_loss: 0.5656\n",
            "Epoch 24/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9910 - loss: 0.0278 - val_accuracy: 0.9204 - val_loss: 0.5891\n",
            "Epoch 25/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9931 - loss: 0.0214 - val_accuracy: 0.9046 - val_loss: 0.5325\n",
            "Epoch 26/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9887 - loss: 0.0351 - val_accuracy: 0.9143 - val_loss: 0.5705\n",
            "Epoch 27/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9906 - loss: 0.0361 - val_accuracy: 0.9125 - val_loss: 0.5685\n",
            "Epoch 28/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9108 - val_loss: 0.6392\n",
            "Epoch 29/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9967 - loss: 0.0090 - val_accuracy: 0.9160 - val_loss: 0.6014\n",
            "Epoch 30/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9961 - loss: 0.0120 - val_accuracy: 0.9151 - val_loss: 0.5842\n",
            "Epoch 31/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9978 - loss: 0.0084 - val_accuracy: 0.9151 - val_loss: 0.5869\n",
            "Epoch 32/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9933 - loss: 0.0202 - val_accuracy: 0.9178 - val_loss: 0.5371\n",
            "Epoch 33/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9960 - loss: 0.0125 - val_accuracy: 0.9143 - val_loss: 0.5889\n",
            "Epoch 34/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9958 - loss: 0.0088 - val_accuracy: 0.9221 - val_loss: 0.8195\n",
            "Epoch 35/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9912 - loss: 0.0270 - val_accuracy: 0.9160 - val_loss: 0.6602\n",
            "Epoch 36/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9908 - loss: 0.0249 - val_accuracy: 0.9073 - val_loss: 0.6140\n",
            "Epoch 37/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9169 - val_loss: 0.5824\n",
            "Epoch 38/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.9169 - val_loss: 0.6593\n",
            "Epoch 39/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9967 - loss: 0.0083 - val_accuracy: 0.9169 - val_loss: 0.6899\n",
            "Epoch 40/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9957 - loss: 0.0124 - val_accuracy: 0.8933 - val_loss: 0.5862\n",
            "Epoch 41/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9875 - loss: 0.0325 - val_accuracy: 0.9108 - val_loss: 0.6502\n",
            "Epoch 42/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9952 - loss: 0.0162 - val_accuracy: 0.9151 - val_loss: 0.6572\n",
            "Epoch 43/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9081 - val_loss: 0.7521\n",
            "Epoch 44/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.9125 - val_loss: 0.7608\n",
            "Epoch 45/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9099 - val_loss: 0.8114\n",
            "Epoch 46/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9967 - loss: 0.0118 - val_accuracy: 0.9108 - val_loss: 0.7579\n",
            "Epoch 47/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.9099 - val_loss: 0.7302\n",
            "Epoch 48/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9099 - val_loss: 0.7316\n",
            "Epoch 49/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9143 - val_loss: 0.7876\n",
            "Epoch 50/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9968 - loss: 0.0079 - val_accuracy: 0.9134 - val_loss: 0.8845\n",
            "Epoch 51/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9929 - loss: 0.0168 - val_accuracy: 0.9143 - val_loss: 0.5505\n",
            "Epoch 52/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9954 - loss: 0.0107 - val_accuracy: 0.9081 - val_loss: 0.6871\n",
            "Epoch 53/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9950 - loss: 0.0194 - val_accuracy: 0.9169 - val_loss: 0.7735\n",
            "Epoch 54/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9941 - loss: 0.0218 - val_accuracy: 0.9134 - val_loss: 0.5856\n",
            "Epoch 55/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9933 - loss: 0.0196 - val_accuracy: 0.9108 - val_loss: 0.8072\n",
            "Epoch 56/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9941 - loss: 0.0190 - val_accuracy: 0.9160 - val_loss: 0.8729\n",
            "Epoch 57/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.9081 - val_loss: 0.8586\n",
            "Epoch 58/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 0.9046 - val_loss: 0.9104\n",
            "Epoch 59/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.9134 - val_loss: 0.7856\n",
            "Epoch 60/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9944 - loss: 0.0134 - val_accuracy: 0.9011 - val_loss: 1.0025\n",
            "Epoch 61/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9975 - loss: 0.0067 - val_accuracy: 0.9125 - val_loss: 0.7551\n",
            "Epoch 62/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9953 - loss: 0.0180 - val_accuracy: 0.9099 - val_loss: 0.7874\n",
            "Epoch 63/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.9151 - val_loss: 0.7967\n",
            "Epoch 64/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9099 - val_loss: 0.9962\n",
            "Epoch 65/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9081 - val_loss: 0.8601\n",
            "Epoch 66/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9955 - loss: 0.0127 - val_accuracy: 0.9029 - val_loss: 0.9211\n",
            "Epoch 67/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9969 - loss: 0.0124 - val_accuracy: 0.8994 - val_loss: 1.1323\n",
            "Epoch 68/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.9090 - val_loss: 0.9890\n",
            "Epoch 69/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9972 - loss: 0.0044 - val_accuracy: 0.9090 - val_loss: 0.8871\n",
            "Epoch 70/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9972 - loss: 0.0094 - val_accuracy: 0.9011 - val_loss: 0.8234\n",
            "Epoch 71/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 0.9055 - val_loss: 0.7827\n",
            "Epoch 72/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9169 - val_loss: 0.8046\n",
            "Epoch 73/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9978 - loss: 0.0083 - val_accuracy: 0.9134 - val_loss: 0.8345\n",
            "Epoch 74/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9954 - loss: 0.0159 - val_accuracy: 0.9064 - val_loss: 0.8037\n",
            "Epoch 75/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9919 - loss: 0.0240 - val_accuracy: 0.9038 - val_loss: 0.8814\n",
            "Epoch 76/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.9099 - val_loss: 0.8565\n",
            "Epoch 77/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9108 - val_loss: 0.8597\n",
            "Epoch 78/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9982 - loss: 0.0083 - val_accuracy: 0.9099 - val_loss: 0.9493\n",
            "Epoch 79/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.9046 - val_loss: 1.1556\n",
            "Epoch 80/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9081 - val_loss: 1.0765\n",
            "Epoch 81/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.8924 - val_loss: 1.0654\n",
            "Epoch 82/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9958 - loss: 0.0167 - val_accuracy: 0.9160 - val_loss: 0.9356\n",
            "Epoch 83/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9994 - loss: 0.0042 - val_accuracy: 0.9055 - val_loss: 1.0744\n",
            "Epoch 84/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9983 - loss: 0.0037 - val_accuracy: 0.9081 - val_loss: 1.0237\n",
            "Epoch 85/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 0.9038 - val_loss: 0.8144\n",
            "Epoch 86/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9937 - loss: 0.0146 - val_accuracy: 0.9125 - val_loss: 0.9795\n",
            "Epoch 87/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.9125 - val_loss: 0.9408\n",
            "Epoch 88/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9972 - loss: 0.0113 - val_accuracy: 0.9151 - val_loss: 0.8695\n",
            "Epoch 89/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9969 - loss: 0.0081 - val_accuracy: 0.9046 - val_loss: 1.0381\n",
            "Epoch 90/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.9134 - val_loss: 1.0898\n",
            "Epoch 91/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.8976 - val_loss: 1.1658\n",
            "Epoch 92/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9947 - loss: 0.0173 - val_accuracy: 0.9125 - val_loss: 1.0594\n",
            "Epoch 93/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9956 - loss: 0.0171 - val_accuracy: 0.9055 - val_loss: 0.9952\n",
            "Epoch 94/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9971 - loss: 0.0074 - val_accuracy: 0.9151 - val_loss: 0.9531\n",
            "Epoch 95/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9064 - val_loss: 0.8818\n",
            "Epoch 96/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9964 - loss: 0.0088 - val_accuracy: 0.9125 - val_loss: 0.8766\n",
            "Epoch 97/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9125 - val_loss: 1.0792\n",
            "Epoch 98/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 0.9099 - val_loss: 1.0683\n",
            "Epoch 99/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.9099 - val_loss: 1.0352\n",
            "Epoch 100/100\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.8994 - val_loss: 1.2572\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9006 - loss: 0.8747\n",
            "Test accuracy: 0.9237\n"
          ]
        }
      ]
    }
  ]
}